from selenium import webdriver
import time
import pandas as pd
import math
from selenium.webdriver.common.keys import Keys
import numpy as np
#5
#5
#160
#150


class Scraper:
    """The Scraper class provides method to repeatedly refresh and scrape primedope's poker variance calculator.
    This is by no means a bug free or comprehensive solution. I wrote this in an afternoon b/c my brother is a bum
    who can't code"""

    def __init__(self, wr_bb_100=5, wr_observed=5, std_dev=160, hands=150):
        """Initialization. each param for the poker variance calculator can be set.
        Every time the the page is refresh, the selenium web browser will input these parameters in into the calculator"""
        url = "https://www.primedope.com/poker-variance-calculator/"
        self.driver = webdriver.Chrome()
        self.driver.get(url)
        self.wr_bb_100 = wr_bb_100
        self.wr_observed = wr_observed
        self.std_dev = std_dev
        self.hands = hands
        self.data = []
        self.sample_names = None
        self.table = None
        self.__input_params()

    def __input_params(self):
        """Code for selenium browser to input parameters into calculator, also hits calculates and
        waits for table to be generated"""
        in_param = self.driver.find_element_by_xpath("//*[@id=\"winrate\"]")
        in_param.clear()
        in_param.send_keys(self.wr_bb_100)

        in_param = self.driver.find_element_by_xpath("//*[@id=\"observed_winrate\"]")
        in_param.clear()
        in_param.send_keys(self.wr_observed)

        in_param = self.driver.find_element_by_xpath("//*[@id=\"sd\"]")
        in_param.clear()
        in_param.send_keys(self.std_dev)

        in_param = self.driver.find_element_by_xpath("//*[@id=\"hande\"]")
        in_param.clear()
        in_param.send_keys(self.hands)

        self.driver.find_element_by_xpath("//*[@id=\"enterData\"]/table/tbody/tr[5]/td[1]/button").click()
        time.sleep(3)
        self.__get_table()

    def __get_table(self):
        """scrapes table from the site's html and places into table variable"""
        self.table = self.driver.find_element_by_xpath("//*[@id=\"chart_div\"]/div/div[1]/div/div/table")

    def __get_headers(self):
        # create list of column headers
        """scrapes headers from table for use in pandas dataframe"""
        headers = self.table.find_element_by_tag_name("thead")
        columns = headers.find_elements_by_tag_name("th")
        self.sample_names = [x.get_attribute('textContent') for x in columns]

    def __get_last_row(self):
        """scrapes final row from table.
        Alex told me he only cared about final value of simulation so thats all this function does"""
        # get rows of table data
        rows = self.table.find_element_by_tag_name("tbody").find_elements_by_tag_name("tr")
        # convert html elements to ints and store in 2d list
        last = [num.get_attribute('textContent') for num in rows[-1].find_elements_by_tag_name("td")]
        return last

    def __refresh_page(self):

        self.driver.refresh()
        self.__input_params()

    def scrape_page_x_times(self, scrapes, file_name="raw_data.csv"):

        self.__get_headers()

        for i in range(0, scrapes):
            self.data.append(self.__get_last_row())
            if i != scrapes-1:
                self.__refresh_page()
            print(i)

        df = pd.DataFrame(self.data, columns=self.sample_names)
        df.to_csv(file_name, mode='w', index=True, header=True)

    def average_with_rake(self, rake=3):
        """averages all values generated by calculator:
        (sum(positive values)*(1-rake/100)+sum(negative values))/number of values"""
        rake = 1 - rake/100.0
        print(rake)
        print(self.data)
        sum_final_vals = 0
        num_entries = 0
        for i in self.data:
            for j in range(1,len(i)):
                #this looks weird but if a comma is present in the number than converting from str to int with cause an error
                converted_num = int((i[j]).replace(',', '')) if isinstance(i[j], str) else i[j]
                if converted_num > 0:
                    sum_final_vals += rake*converted_num
                else:
                    sum_final_vals += converted_num
                num_entries += 1
        return sum_final_vals/num_entries

    def average_with_rake_exclude_first_x_cols(self, rake=3, cols=8):
        """does the same thing as the other average with rake but can be used to exclude some of the different samples
        to average best and worst with 20 samples, cols=6
        to only average samples 1-20, cols=8"""
        rake = 1 - rake/100.0
        sum_final_vals = 0
        num_entries = 0

        #this loop finds the average
        for i in self.data:
            for j in range(cols, len(i)):
                # this looks weird but if a comma is present in the number than converting from str to int with cause an error
                converted_num = int((i[j]).replace(',', '')) if isinstance(i[j], str) else i[j]
                if converted_num > 0:
                    sum_final_vals += rake*converted_num
                else:
                    sum_final_vals += converted_num
                num_entries += 1

        return sum_final_vals/num_entries

    def sort_data_by_plus_minus(self, bw=False, file_name="plus_minus.csv"):
        """
        Takes raw data from scrapes and sorts into a two column dataframe with positive values in first column
        and negative values in second then prints table to a .csv file.
        if bw is set to False(default setting) then only samples 1-20 will be looked at
        """
        positive = []
        negative = []
        first_index = 6 if bw else 8
        for i in self.data:
            for j in range(first_index, len(i)):
                converted_num = int((i[j]).replace(',', '')) if isinstance(i[j], str) else i[j]
                if converted_num > 0:
                    positive.append(converted_num)
                else:
                    negative.append(converted_num)
        #pandas stuff and writing to csv
        df = pd.DataFrame(positive)
        df1 = pd.DataFrame(negative)
        final = pd.concat([df, df1], ignore_index=True, axis=1)
        final.to_csv(file_name, mode='w', index=False, header=False)

    def read_raw_file_from_csv(self, file_name):
        """
        reads raw data only useful if you want to relook a data from previous scrape.
        puts data into self.data
        """
        df = pd.read_csv(file_name, index_col=0)
        self.data = df.to_numpy()

    def read_plus_minus_file_from_csv(self, file_name):
        """
        reads from file to get to get two column dataframe with positive values in first column
        and negative values in second then returns numpy array of table
        """
        df = pd.read_csv(file_name, index_col=0)
        return df.to_numpy()

    @staticmethod
    #input should be two column numpy array
    def get_avg_of_plus_minus(two_col_array):
        """
        pretty much does what it says, rake is set to 3%
        :param two_col_array: takes two column numpy array of positive and negative values of scrape
        :return: average of two column numpy array
        """
        rake = 0.97
        sum = 0
        entries = 0

        for i in two_col_array:
            for j in i:
                if not math.isnan(j):
                    sum += j if j <= 0 else j*rake
                    entries += 1

        return sum/entries



